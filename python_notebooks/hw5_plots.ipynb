{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2c17832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "96d3c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_url = 'https://raw.githubusercontent.com/UIUC-iSchool-DataViz/is445_data/main/building_inventory.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "11922bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "building = pd.read_csv(building_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6148b7c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRowsError",
     "evalue": "The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxRowsError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/is445/lib/python3.9/site-packages/altair/vegalite/v5/api.py:1998\u001b[0m, in \u001b[0;36mTopLevelMixin.to_dict\u001b[0;34m(self, validate, format, ignore, context)\u001b[0m\n\u001b[1;32m   1995\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1996\u001b[0m         \u001b[38;5;66;03m# Non-narwhalifiable type supported by Altair, such as dict\u001b[39;00m\n\u001b[1;32m   1997\u001b[0m         data \u001b[38;5;241m=\u001b[39m original_data\n\u001b[0;32m-> 1998\u001b[0m     copy\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1999\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# remaining to_dict calls are not at top level\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/is445/lib/python3.9/site-packages/altair/vegalite/v5/api.py:283\u001b[0m, in \u001b[0;36m_prepare_data\u001b[0;34m(data, context)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_data_type(data):\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;241m:=\u001b[39m data_transformers\u001b[38;5;241m.\u001b[39mget():\n\u001b[0;32m--> 283\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_native\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_through\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# convert string input to a URLData\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/is445/lib/python3.9/site-packages/altair/vegalite/data.py:42\u001b[0m, in \u001b[0;36mdefault_data_transformer\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pipe\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m to_values(\u001b[43mlimit_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/is445/lib/python3.9/site-packages/altair/utils/data.py:165\u001b[0m, in \u001b[0;36mlimit_rows\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m    162\u001b[0m     values \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_rows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m>\u001b[39m max_rows:\n\u001b[0;32m--> 165\u001b[0m     \u001b[43mraise_max_rows_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/miniconda3/envs/is445/lib/python3.9/site-packages/altair/utils/data.py:148\u001b[0m, in \u001b[0;36mlimit_rows.<locals>.raise_max_rows_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_max_rows_error\u001b[39m():\n\u001b[1;32m    136\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of rows in your dataset is greater \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan the maximum allowed (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon how to plot large datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m     )\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRowsError(msg)\n",
      "\u001b[0;31mMaxRowsError\u001b[0m: The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets."
     ]
    },
    {
     "data": {
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_subset = building[['Agency Name', 'County', 'Year Constructed', 'Square Footage', 'Usage Description', 'Bldg Status']].copy()\n",
    "building_subset = building_subset.dropna(subset=['Year Constructed', 'Square Footage'])\n",
    "\n",
    "brush = alt.selection_interval(encodings=['x','y'])\n",
    "\n",
    "chart1 = alt.Chart(building_subset).mark_rect().encode(\n",
    "    alt.X(\"Square Footage:Q\", bin=alt.Bin(maxbins=10)),\n",
    "    alt.Y(\"Agency Name:O\"),\n",
    "    alt.Color(\"count()\")\n",
    ").properties(\n",
    "   height=400,\n",
    ").add_params(brush)\n",
    "\n",
    "chart2 = alt.Chart(building_subset).mark_bar().encode(\n",
    "    alt.X(\"Year Constructed:Q\", bin=True),\n",
    "    alt.Y('count()'),\n",
    "    alt.Color(\"Usage Description:N\")\n",
    ").transform_filter(\n",
    "    brush\n",
    ")\n",
    "\n",
    "chart1_subset = (chart1.properties(width=400) | chart2.properties(width=400))\n",
    "\n",
    "chart1_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18385a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_subset.save(myJekyllDir + 'building_analysis1_subset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "291ff40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1584791"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.stat(myJekyllDir + 'building_analysis1_subset.json').st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a8615a89",
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRowsError",
     "evalue": "The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxRowsError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/is445/lib/python3.9/site-packages/altair/vegalite/v5/api.py:1998\u001b[0m, in \u001b[0;36mTopLevelMixin.to_dict\u001b[0;34m(self, validate, format, ignore, context)\u001b[0m\n\u001b[1;32m   1995\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1996\u001b[0m         \u001b[38;5;66;03m# Non-narwhalifiable type supported by Altair, such as dict\u001b[39;00m\n\u001b[1;32m   1997\u001b[0m         data \u001b[38;5;241m=\u001b[39m original_data\n\u001b[0;32m-> 1998\u001b[0m     copy\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1999\u001b[0m     context[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# remaining to_dict calls are not at top level\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/is445/lib/python3.9/site-packages/altair/vegalite/v5/api.py:283\u001b[0m, in \u001b[0;36m_prepare_data\u001b[0;34m(data, context)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_data_type(data):\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;241m:=\u001b[39m data_transformers\u001b[38;5;241m.\u001b[39mget():\n\u001b[0;32m--> 283\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_native\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_through\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# convert string input to a URLData\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/is445/lib/python3.9/site-packages/altair/vegalite/data.py:42\u001b[0m, in \u001b[0;36mdefault_data_transformer\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pipe\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m to_values(\u001b[43mlimit_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/is445/lib/python3.9/site-packages/altair/utils/data.py:165\u001b[0m, in \u001b[0;36mlimit_rows\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m    162\u001b[0m     values \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_rows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m>\u001b[39m max_rows:\n\u001b[0;32m--> 165\u001b[0m     \u001b[43mraise_max_rows_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/miniconda3/envs/is445/lib/python3.9/site-packages/altair/utils/data.py:148\u001b[0m, in \u001b[0;36mlimit_rows.<locals>.raise_max_rows_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_max_rows_error\u001b[39m():\n\u001b[1;32m    136\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of rows in your dataset is greater \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan the maximum allowed (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon how to plot large datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m     )\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRowsError(msg)\n",
      "\u001b[0;31mMaxRowsError\u001b[0m: The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets."
     ]
    },
    {
     "data": {
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brush2 = alt.selection_interval(encodings=['x'])\n",
    "\n",
    "chart3 = alt.Chart(building_subset).mark_bar().encode(\n",
    "    alt.X(\"Bldg Status:N\"),\n",
    "    alt.Y(\"sum(Square Footage):Q\"),\n",
    "    alt.Color(\"Usage Description:N\"),\n",
    "    tooltip=['Bldg Status', 'Usage Description', 'sum(Square Footage)']\n",
    ").properties(\n",
    "    width=300,\n",
    ").add_params(\n",
    "    brush2\n",
    ")\n",
    "\n",
    "\n",
    "chart4 = alt.Chart(building_subset).mark_circle().encode(\n",
    "    alt.X(\"Year Constructed:Q\"),\n",
    "    alt.Y(\"County:N\"),\n",
    "    alt.Size(\"Square Footage:Q\"),\n",
    "    alt.Color(\"Agency Name:N\"),\n",
    "    tooltip=['County', 'Year Constructed', 'Square Footage', 'Agency Name']\n",
    ").properties(\n",
    "    width=500\n",
    ").transform_filter(brush2)\n",
    "\n",
    "chart2_subset = (chart3 | chart4)\n",
    "\n",
    "chart2_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1fddaf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart2_subset.save(myJekyllDir + 'building_analysis2_subset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51e1ec69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1585258"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.stat(myJekyllDir + 'building_analysis2_subset.json').st_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is445",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
